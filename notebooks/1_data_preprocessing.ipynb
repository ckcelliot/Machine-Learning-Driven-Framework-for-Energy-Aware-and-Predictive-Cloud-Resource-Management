{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6361b782",
   "metadata": {},
   "source": [
    "Download the Bitbrains Dataset inside Jupyter Notebook\n",
    "\n",
    "The Bitbrains dataset is hosted on GitHub, so we can download it using wget or requests inside the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110a8a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests\n",
    "pip install pandas\n",
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b63d9d6",
   "metadata": {},
   "source": [
    "Used kagglehub to download gwa-bitbrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574c1def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azka/Downloads/Java/.venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/azka/.cache/kagglehub/datasets/gauravdhamane/gwa-bitbrains/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"gauravdhamane/gwa-bitbrains\")\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f895b7",
   "metadata": {},
   "source": [
    "Copied fastStorage into your project:\n",
    "/Users/azka/Desktop/Java/data/fastStorage/2013-8/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "653170ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied fastStorage to: /Users/azka/Desktop/Java/data/fastStorage\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "src = \"/Users/azka/.cache/kagglehub/datasets/gauravdhamane/gwa-bitbrains/versions/1/fastStorage\"\n",
    "dst = \"/Users/azka/Desktop/Java/data/fastStorage\"\n",
    "\n",
    "shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "\n",
    "print(\"Copied fastStorage to:\", dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f78777a",
   "metadata": {},
   "source": [
    "According to your spec:\n",
    "\n",
    "Bitbrains (GWA-T-12, fastStorage)\n",
    "\n",
    "    Main dataset for model training + evaluation + CloudSim experiments.\n",
    "\n",
    "    We already downloaded this. âœ…\n",
    "\n",
    "Google Cluster Trace (small sample)\n",
    "\n",
    "    Secondary dataset to show generality (optional but good for dissertation).\n",
    "\n",
    "    We can use a sampled Kaggle version later, after the full pipeline works on Bitbrains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3042d85",
   "metadata": {},
   "source": [
    "roup this into three main phases:\n",
    "\n",
    "A) ML prediction pipeline (Python)\n",
    "\n",
    "B) CloudSim scheduling + energy simulation (Java)\n",
    "\n",
    "C) Evaluation, graphs, poster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9783a",
   "metadata": {},
   "source": [
    "Phase A â€” ML Pipeline on Bitbrains (Python / Jupyter)\n",
    "\n",
    "A1. Preprocess Bitbrains into one clean dataset\n",
    "\n",
    "Input: many CSVs: fastStorage/2013-8/1.csv ... 1250.csv\n",
    "\n",
    "Tasks:\n",
    "\n",
    "Load all VM files.\n",
    "\n",
    "Convert Timestamp [ms] â†’ datetime.\n",
    "\n",
    "Compute mem_usage_percent = Memory usage / Memory capacity * 100.\n",
    "\n",
    "Keep only: timestamp, vm_id, cpu_usage_percent, mem_usage_percent.\n",
    "\n",
    "Resample to a fixed step (e.g. 5 minutes).\n",
    "\n",
    "Combine all VMs into one CSV.\n",
    "\n",
    "Output:\n",
    "ðŸ‘‰ bitbrains_clean_all.csv\n",
    "\n",
    "This is what we are about to implement next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d0a4fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_DIR: /Users/azka/Downloads/Java/data/fastStorage/2013-8\n",
      "OUTPUT_PATH: /Users/azka/Downloads/Java/data/bitbrains_clean_all.csv\n",
      "            timestamp  cpu_usage_percent  mem_usage_percent  vm_id\n",
      "0 2013-08-12 13:40:00          93.233333           9.133331      1\n",
      "1 2013-08-12 13:45:00          93.050000          10.066664      1\n",
      "2 2013-08-12 13:50:00          89.150000          13.333330      1\n",
      "3 2013-08-12 13:55:00          90.050000          27.999996      1\n",
      "4 2013-08-12 14:00:00          93.566667          13.866664      1\n",
      "Total VM files found: 1250\n",
      "First few files: ['/Users/azka/Downloads/Java/data/fastStorage/2013-8/1.csv', '/Users/azka/Downloads/Java/data/fastStorage/2013-8/10.csv', '/Users/azka/Downloads/Java/data/fastStorage/2013-8/100.csv', '/Users/azka/Downloads/Java/data/fastStorage/2013-8/1000.csv', '/Users/azka/Downloads/Java/data/fastStorage/2013-8/1001.csv']\n",
      "Processed 100 VM files...\n",
      "Processed 200 VM files...\n",
      "Processed 300 VM files...\n",
      "Processed 400 VM files...\n",
      "Processed 500 VM files...\n",
      "Processed 600 VM files...\n",
      "Processed 700 VM files...\n",
      "Processed 800 VM files...\n",
      "Processed 900 VM files...\n",
      "Processed 1000 VM files...\n",
      "Processed 1100 VM files...\n",
      "Processed 1200 VM files...\n",
      "Total processed VMs: 1250\n",
      "Final shape: (9662443, 4)\n",
      "            timestamp  cpu_usage_percent  mem_usage_percent  vm_id\n",
      "0 2013-08-12 13:40:00          93.233333           9.133331      1\n",
      "1 2013-08-12 13:45:00          93.050000          10.066664      1\n",
      "2 2013-08-12 13:50:00          89.150000          13.333330      1\n",
      "3 2013-08-12 13:55:00          90.050000          27.999996      1\n",
      "4 2013-08-12 14:00:00          93.566667          13.866664      1\n",
      "Saved cleaned dataset to: /Users/azka/Downloads/Java/data/bitbrains_clean_all.csv\n",
      "File exists? True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# âœ… Use the correct base directory\n",
    "BASE_DIR = \"/Users/azka/Downloads/Java\"\n",
    "\n",
    "RAW_DIR = os.path.join(BASE_DIR, \"data\", \"fastStorage\", \"2013-8\")\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"data\", \"bitbrains_clean_all.csv\")\n",
    "\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n",
    "print(\"OUTPUT_PATH:\", OUTPUT_PATH)\n",
    "\n",
    "\n",
    "def process_vm_file(file_path: str, vm_id: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load one Bitbrains VM CSV and return a cleaned time series:\n",
    "    timestamp, vm_id, cpu_usage_percent, mem_usage_percent\n",
    "    \"\"\"\n",
    "    # 1) Load with correct separator\n",
    "    df = pd.read_csv(file_path, sep=';', engine='python')\n",
    "\n",
    "    # 2) Strip whitespace from column names\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    # 3) Sanity check\n",
    "    required = [\n",
    "        \"Timestamp [ms]\",\n",
    "        \"CPU usage [%]\",\n",
    "        \"Memory capacity provisioned [KB]\",\n",
    "        \"Memory usage [KB]\",\n",
    "    ]\n",
    "    for col in required:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing expected column {col} in {file_path}\")\n",
    "\n",
    "    # 4) âœ… Convert timestamp from **seconds** â†’ datetime\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"Timestamp [ms]\"], unit=\"s\")\n",
    "\n",
    "    # 5) Memory usage in percent\n",
    "    df[\"mem_usage_percent\"] = (\n",
    "        df[\"Memory usage [KB]\"] / df[\"Memory capacity provisioned [KB]\"]\n",
    "    ) * 100.0\n",
    "\n",
    "    # 6) Keep only what we need\n",
    "    out = df[[\"timestamp\", \"CPU usage [%]\", \"mem_usage_percent\"]].copy()\n",
    "    out = out.rename(columns={\"CPU usage [%]\": \"cpu_usage_percent\"})\n",
    "\n",
    "    # 7) Sort + drop NaNs\n",
    "    out = out.sort_values(\"timestamp\").dropna()\n",
    "\n",
    "    # 8) Resample to fixed 5-minute intervals\n",
    "    out = (\n",
    "        out\n",
    "        .set_index(\"timestamp\")\n",
    "        .resample(\"5min\")   # 'T' is deprecated\n",
    "        .mean()\n",
    "        .interpolate()\n",
    "    )\n",
    "\n",
    "    # 9) Add VM id\n",
    "    out[\"vm_id\"] = vm_id\n",
    "    out = out.reset_index()\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# âœ… Test on one file from Downloads path\n",
    "test_file = \"/Users/azka/Downloads/Java/data/fastStorage/2013-8/1.csv\"\n",
    "test_df = process_vm_file(test_file, vm_id=1)\n",
    "print(test_df.head())\n",
    "\n",
    "# List all VM CSV files\n",
    "all_files = sorted(glob.glob(os.path.join(RAW_DIR, \"*.csv\")))\n",
    "print(\"Total VM files found:\", len(all_files))\n",
    "print(\"First few files:\", all_files[:5])\n",
    "\n",
    "combined = []\n",
    "\n",
    "for i, file_path in enumerate(all_files, start=1):\n",
    "    vm_str = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    try:\n",
    "        vm_id = int(vm_str)\n",
    "    except ValueError:\n",
    "        print(f\"Skipping non-numeric VM file: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        vm_df = process_vm_file(file_path, vm_id)\n",
    "        combined.append(vm_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processed {i} VM files...\")\n",
    "\n",
    "print(\"Total processed VMs:\", len(combined))\n",
    "\n",
    "if not combined:\n",
    "    raise RuntimeError(\"No VM files processed successfully!\")\n",
    "\n",
    "df_all = pd.concat(combined, axis=0, ignore_index=True)\n",
    "\n",
    "print(\"Final shape:\", df_all.shape)\n",
    "print(df_all.head())\n",
    "\n",
    "# âœ… Save to Downloads/Java/data\n",
    "df_all.to_csv(OUTPUT_PATH, index=False)\n",
    "print(\"Saved cleaned dataset to:\", OUTPUT_PATH)\n",
    "\n",
    "# Quick existence check\n",
    "print(\"File exists?\", os.path.exists(OUTPUT_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e06e088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9662443 entries, 0 to 9662442\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   timestamp          datetime64[ns]\n",
      " 1   cpu_usage_percent  float64       \n",
      " 2   mem_usage_percent  float64       \n",
      " 3   vm_id              int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1)\n",
      "memory usage: 294.9 MB\n",
      "Min timestamp: 2013-08-12 13:40:00\n",
      "Max timestamp: 2013-09-11 13:35:00\n",
      "Number of VMs: 1250\n",
      "VM id sample: [   1   10  100 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009  101\n",
      " 1010 1011 1012 1013 1014 1015]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azka/Downloads/Java/.venv/lib/python3.14/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "timestamp            0.0\n",
       "cpu_usage_percent    0.0\n",
       "mem_usage_percent    0.0\n",
       "vm_id                0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CLEAN_PATH = \"/Users/azka/Downloads/Java/data/bitbrains_clean_all.csv\"\n",
    "\n",
    "df = pd.read_csv(CLEAN_PATH, parse_dates=[\"timestamp\"])\n",
    "df.head()\n",
    "df.info()\n",
    "df.describe()\n",
    "print(\"Min timestamp:\", df[\"timestamp\"].min())\n",
    "print(\"Max timestamp:\", df[\"timestamp\"].max())\n",
    "print(\"Number of VMs:\", df[\"vm_id\"].nunique())\n",
    "print(\"VM id sample:\", df[\"vm_id\"].unique()[:20])\n",
    "df.isna().mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b49c556",
   "metadata": {},
   "source": [
    "Dataset Status (Excellent Quality)\n",
    "\n",
    "âœ” 9.66 million rows â€” good for ML\n",
    "\n",
    "âœ” 1250 VMs\n",
    "\n",
    "âœ” Clean timestamps from 2013-08-12 â†’ 2013-09-11\n",
    "\n",
    "âœ” No missing values\n",
    "\n",
    "âœ” CPU & Memory usage percentages look valid\n",
    "\n",
    "âœ” Uniform 5-minute intervals (our resampling worked)\n",
    "\n",
    "This is now a gold-standard workload time-series dataset ready for:\n",
    "\n",
    "forecasting\n",
    "\n",
    "classification\n",
    "\n",
    "autoscaling simulation\n",
    "\n",
    "anomaly detection\n",
    "\n",
    "And EXACTLY aligned with your project goals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f8da5",
   "metadata": {},
   "source": [
    "A2. Prepare data for forecasting\n",
    "\n",
    "Decide prediction horizon (e.g. predict 1 step ahead = next 5 minutes).\n",
    "\n",
    "Create sliding windows for LSTM:\n",
    "\n",
    "Input window length (e.g. last 12 steps = last 1 hour).\n",
    "\n",
    "Output = next CPU% (and maybe memory%).\n",
    "\n",
    "For XGBoost:\n",
    "\n",
    "Create lag features + simple statistics (mean of last N steps, etc.).\n",
    "\n",
    "Split into train / validation / test (e.g. 70 / 15 / 15).\n",
    "\n",
    "Outputs:\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8758068c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33ab5bbb",
   "metadata": {},
   "source": [
    "A3. Train ML models\n",
    "\n",
    "Models:\n",
    "\n",
    "XGBoost Regressor for CPU% (and possibly separate for memory%).\n",
    "\n",
    "LSTM (Keras) for time-series forecasting.\n",
    "\n",
    "Train both models, tune basic hyperparameters.\n",
    "\n",
    "Evaluate with:\n",
    "\n",
    "RMSE, MAE, MAPE\n",
    "\n",
    "Plots of predicted vs actual CPU% for some VMs.\n",
    "\n",
    "Outputs:\n",
    "\n",
    "xgb_model_cpu.pkl, lstm_model_cpu.h5\n",
    "\n",
    "Notebook with evaluation plots for your repor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c7ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6633530e",
   "metadata": {},
   "source": [
    "A4. Generate prediction traces for CloudSim\n",
    "\n",
    "Use best model (e.g. LSTM) on test period to produce a full trace:\n",
    "\n",
    "For each VM and each time step in simulation horizon:\n",
    "\n",
    "Predicted cpu_usage_percent (and optionally memory).\n",
    "\n",
    "Save in a format CloudSim can read, e.g.:\n",
    "\n",
    "time, vm_id, predicted_cpu, predicted_mem\n",
    "\n",
    "2013-08-12 10:00, 1, 3.5, 5.0\n",
    "\n",
    "2013-08-12 10:05, 1, 3.8, 5.1\n",
    "...\n",
    "\n",
    "\n",
    "Output:\n",
    "ðŸ‘‰ predicted_traces.csv\n",
    "\n",
    "This file is the bridge from Python (ML) â†’ Java (CloudSim)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fe8896",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
