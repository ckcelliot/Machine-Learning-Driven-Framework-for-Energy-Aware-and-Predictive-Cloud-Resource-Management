{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aeb423b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML_DATA_PATH: /Users/azka/Downloads/Java/data/bitbrains_ml_windows.csv\n",
      "PRED_OUTPUT_PATH: /Users/azka/Downloads/Java/data/bitbrains_predictions_for_cloudsim.csv\n",
      "Shape: (9640028, 4)\n",
      "vm_id                  int64\n",
      "features              object\n",
      "target_cpu_future    float64\n",
      "target_high_load       int64\n",
      "dtype: object\n",
      "Columns: ['vm_id', 'features', 'target_cpu_future', 'target_high_load']\n",
      "Parsed one example: [93.23333333, 93.05, 89.15, 90.05, 93.56666667, 93.25, 92.75, 86.78333333, 89.51666667, 95.08333333, 94.25, 55.41666667]\n",
      "Length of example feature vector: 12\n",
      "Feature matrix shape: (9640028, 12)\n",
      "Feature parsing time: 35.53 seconds\n",
      "X shape: (9640028, 12)\n",
      "y_reg shape: (9640028,)\n",
      "y_cls shape: (9640028,)\n",
      "Train size (reg): (7712022, 12) Test size (reg): (1928006, 12)\n",
      "Train size (cls): (7712022, 12) Test size (cls): (1928006, 12)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 0. Imports & Paths\n",
    "# ============================================\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ---- Adjust paths if needed ----\n",
    "DATA_DIR = \"/Users/azka/Downloads/Java/data\"\n",
    "ML_DATA_PATH = os.path.join(DATA_DIR, \"bitbrains_ml_windows.csv\")\n",
    "PRED_OUTPUT_PATH = os.path.join(DATA_DIR, \"bitbrains_predictions_for_cloudsim.csv\")\n",
    "\n",
    "print(\"ML_DATA_PATH:\", ML_DATA_PATH)\n",
    "print(\"PRED_OUTPUT_PATH:\", PRED_OUTPUT_PATH)\n",
    "\n",
    "# ============================================\n",
    "# 1. Load ML dataset\n",
    "# ============================================\n",
    "df = pd.read_csv(ML_DATA_PATH)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df.dtypes)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "df.head()\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 2. Parse 'features' column (NumPy-style strings)\n",
    "#    Example string: \"[93.23 85.11 77.92]\"\n",
    "# ============================================\n",
    "\n",
    "def parse_numpy_array(x: str):\n",
    "    \"\"\"\n",
    "    Convert a NumPy-style string array like:\n",
    "        \"[93.23333333 93.05 89.15]\"\n",
    "    into a Python list of floats: [93.2333, 93.05, 89.15]\n",
    "    \"\"\"\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        # Already parsed\n",
    "        return list(x)\n",
    "\n",
    "    if not isinstance(x, str):\n",
    "        raise ValueError(f\"Unexpected features type: {type(x)}\")\n",
    "\n",
    "    s = x.strip()\n",
    "    # Normalize whitespace\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        inner = s[1:-1].strip()\n",
    "        if inner == \"\":\n",
    "            return []\n",
    "        parts = inner.split(\" \")\n",
    "        return [float(p) for p in parts]\n",
    "\n",
    "    raise ValueError(f\"Invalid array string: {x[:50]}...\")\n",
    "\n",
    "# Apply parser\n",
    "t0 = time.time()\n",
    "feat_list = df[\"features\"].apply(parse_numpy_array)\n",
    "print(\"Parsed one example:\", feat_list.iloc[0])\n",
    "print(\"Length of example feature vector:\", len(feat_list.iloc[0]))\n",
    "\n",
    "# Stack into a 2D numpy array: (n_samples, n_features)\n",
    "feat_array = np.stack(feat_list.values)\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"Feature matrix shape:\", feat_array.shape)\n",
    "print(f\"Feature parsing time: {t1 - t0:.2f} seconds\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 3. Prepare targets (regression + classification)\n",
    "# ============================================\n",
    "if \"target_cpu_future\" not in df.columns:\n",
    "    raise ValueError(\"Column 'target_cpu_future' not found in dataset!\")\n",
    "\n",
    "if \"target_high_load\" not in df.columns:\n",
    "    raise ValueError(\"Column 'target_high_load' not found in dataset!\")\n",
    "\n",
    "X = feat_array\n",
    "y_reg = df[\"target_cpu_future\"].values\n",
    "y_cls = df[\"target_high_load\"].values.astype(int)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y_reg shape:\", y_reg.shape)\n",
    "print(\"y_cls shape:\", y_cls.shape)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 4. Train / Test split (time-ordered)\n",
    "#    We assume the rows are already in time order.\n",
    "#    We'll use the first 80% for training, last 20% for testing.\n",
    "# ============================================\n",
    "\n",
    "n = X.shape[0]\n",
    "split_idx = int(n * 0.8)\n",
    "\n",
    "X_train_reg, X_test_reg = X[:split_idx], X[split_idx:]\n",
    "y_train_reg, y_test_reg = y_reg[:split_idx], y_reg[split_idx:]\n",
    "\n",
    "X_train_cls, X_test_cls = X[:split_idx], X[split_idx:]\n",
    "y_train_cls, y_test_cls = y_cls[:split_idx], y_cls[split_idx:]\n",
    "\n",
    "print(\"Train size (reg):\", X_train_reg.shape, \"Test size (reg):\", X_test_reg.shape)\n",
    "print(\"Train size (cls):\", X_train_cls.shape, \"Test size (cls):\", X_test_cls.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efdd3987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Trained RandomForestRegressor in 2291.16 seconds\n",
      "âœ… Trained RandomForestClassifier in 563.48 seconds\n",
      "\n",
      "ðŸ“ˆ Regression Metrics (target_cpu_future):\n",
      "  MAE: 0.5698\n",
      "  RÂ² : 0.6356\n",
      "\n",
      "ðŸ“Š Classification Metrics (target_high_load):\n",
      "  Accuracy: 0.9998\n",
      "  F1-score: 0.6859\n",
      "Predicted all rows in 148.08 seconds\n",
      "Prediction dataframe shape: (9640028, 5)\n",
      "âœ… Saved predictions for CloudSim to: /Users/azka/Downloads/Java/data/bitbrains_predictions_for_cloudsim.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 5. Define models (Regressor + Classifier)\n",
    "# ============================================\n",
    "\n",
    "reg_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"rf\", RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "        )),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cls_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"rf\", RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "        )),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# 6. Train models\n",
    "# ============================================\n",
    "\n",
    "# ---- Regression model ----\n",
    "t0 = time.time()\n",
    "reg_model.fit(X_train_reg, y_train_reg)\n",
    "t1 = time.time()\n",
    "print(f\"âœ… Trained RandomForestRegressor in {t1 - t0:.2f} seconds\")\n",
    "\n",
    "# ---- Classification model ----\n",
    "t0 = time.time()\n",
    "cls_model.fit(X_train_cls, y_train_cls)\n",
    "t1 = time.time()\n",
    "print(f\"âœ… Trained RandomForestClassifier in {t1 - t0:.2f} seconds\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 7. Evaluate on test split\n",
    "# ============================================\n",
    "\n",
    "# ---- Regression ----\n",
    "y_pred_reg = reg_model.predict(X_test_reg)\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"\\nðŸ“ˆ Regression Metrics (target_cpu_future):\")\n",
    "print(f\"  MAE: {mae:.4f}\")\n",
    "print(f\"  RÂ² : {r2:.4f}\")\n",
    "\n",
    "# ---- Classification ----\n",
    "y_pred_cls = cls_model.predict(X_test_cls)\n",
    "acc = accuracy_score(y_test_cls, y_pred_cls)\n",
    "f1 = f1_score(y_test_cls, y_pred_cls)\n",
    "\n",
    "print(\"\\nðŸ“Š Classification Metrics (target_high_load):\")\n",
    "print(f\"  Accuracy: {acc:.4f}\")\n",
    "print(f\"  F1-score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 8. Generate predictions for ALL rows (for CloudSim)\n",
    "# ============================================\n",
    "\n",
    "t0 = time.time()\n",
    "pred_cpu_future_all = reg_model.predict(X)\n",
    "pred_high_load_all = cls_model.predict(X)\n",
    "t1 = time.time()\n",
    "print(f\"Predicted all rows in {t1 - t0:.2f} seconds\")\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"vm_id\": df[\"vm_id\"].values,\n",
    "    \"target_cpu_future\": df[\"target_cpu_future\"].values,\n",
    "    \"target_high_load\": df[\"target_high_load\"].values,\n",
    "    \"pred_cpu_future\": pred_cpu_future_all,\n",
    "    \"pred_high_load\": pred_high_load_all,\n",
    "})\n",
    "\n",
    "print(\"Prediction dataframe shape:\", pred_df.shape)\n",
    "pred_df.head()\n",
    "\n",
    "# ============================================\n",
    "# 9. Save predictions to CSV for CloudSim\n",
    "# ============================================\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "pred_df.to_csv(PRED_OUTPUT_PATH, index=False)\n",
    "print(\"âœ… Saved predictions for CloudSim to:\", PRED_OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99406256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (9640028, 5) Index(['vm_id', 'target_cpu_future', 'target_high_load', 'pred_cpu_future',\n",
      "       'pred_high_load'],\n",
      "      dtype='object')\n",
      "After: (9640028, 6)    slot  vm_id  target_cpu_future  target_high_load  pred_cpu_future  \\\n",
      "0     0      1           0.666667                 0        15.810750   \n",
      "1     1      1           0.583333                 0        14.845571   \n",
      "2     2      1           0.583333                 0         9.758000   \n",
      "3     3      1           0.583333                 0         9.291167   \n",
      "4     4      1           0.650000                 0         8.572417   \n",
      "\n",
      "   pred_high_load  \n",
      "0               0  \n",
      "1               0  \n",
      "2               0  \n",
      "3               0  \n",
      "4               0  \n",
      "âœ… Re-saved with slot column at: /Users/azka/Downloads/Java/data/bitbrains_predictions_for_cloudsim.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = \"/Users/azka/Downloads/Java/data\"\n",
    "PRED_OUTPUT_PATH = os.path.join(DATA_DIR, \"bitbrains_predictions_for_cloudsim.csv\")\n",
    "\n",
    "# Load existing predictions\n",
    "pred_df = pd.read_csv(PRED_OUTPUT_PATH)\n",
    "print(\"Before:\", pred_df.shape, pred_df.columns)\n",
    "\n",
    "# Add a synthetic time index (slot)\n",
    "pred_df.insert(0, \"slot\", np.arange(len(pred_df)))  # add as first column\n",
    "\n",
    "print(\"After:\", pred_df.shape, pred_df.head())\n",
    "\n",
    "# Save back (overwrite)\n",
    "pred_df.to_csv(PRED_OUTPUT_PATH, index=False)\n",
    "print(\"âœ… Re-saved with slot column at:\", PRED_OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c7155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
